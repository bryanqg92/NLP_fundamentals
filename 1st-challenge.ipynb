{"cells":[{"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[],"source":["def get_vocab(corpus):    \n","    #separamos y en una única lista de términos\n","    terms = [doc.split() for doc in corpus]\n","    terms = np.concatenate(terms)\n","   \n","    #vector de términos no repetidos\n","    vocab = np.unique(terms)\n","    return vocab"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZxazlF-4H9t","outputId":"666c88a4-5e7a-492b-b208-049999bf16ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["['de' 'dia' 'el' 'es' 'gracias' 'hoy' 'martes' 'muchas' 'que']\n"]}],"source":["vocab = get_vocab(corpus)\n","print(vocab)"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[],"source":["def oneHot(corpus,vocab):    \n","    one_hot = np.zeros((corpus.size, vocab.size))\n","\n","    # Recorrer los documentos y marcar las posiciones correspondientes con un valor de 1\n","    for i, doc in enumerate(corpus):\n","        terms = doc.split()\n","        for term in terms:\n","            j = np.where(vocab == term)[0][0]\n","            one_hot[i, j] = 1\n","\n","    return one_hot"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_L3RF2yP4H9x","outputId":"999313a3-84b7-4934-c54e-c1203b82fdf2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n"," [1. 1. 1. 1. 0. 1. 1. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 1. 1. 0.]]\n"]}],"source":["one_hot= oneHot(corpus,vocab)\n","print(one_hot)"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EwLNAOsR4H9z","outputId":"1f1198f0-e5ba-47c2-a13a-3e5d42571419"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0. 1. 0. 1. 0. 1. 0. 0. 1.]\n"," [1. 1. 1. 1. 0. 1. 2. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 1. 1. 0.]]\n"]}],"source":["def frequency_vectors(corpus, vocab):\n","    freq_matrix = np.zeros((len(corpus), len(vocab)))\n","\n","    for i, doc in enumerate(corpus):\n","        terms = doc.split()\n","        term_counts = np.bincount([np.where(vocab == term)[0][0] for term in terms if term in vocab])\n","        freq_matrix[i, :len(term_counts)] = term_counts\n","\n","    return freq_matrix\n","\n","freq_matrix = frequency_vectors(corpus, vocab)\n","print(freq_matrix)\n"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waG_oWtpJjRw","outputId":"7a8a3a60-01fc-456e-8ab8-1c3bb57ab1a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.         0.         0.         0.         0.         0.\n","  0.         0.         0.40546511]\n"," [0.40546511 0.         0.40546511 0.         0.         0.\n","  0.         0.         0.        ]\n"," [0.         0.         0.         0.         0.40546511 0.\n","  0.         0.40546511 0.        ]]\n"]}],"source":["def tfidf_representation(corpus):\n","    # Obtener el vocabulario\n","    vocab = get_vocab(corpus)\n","\n","    # Obtener la matriz de frecuencia\n","    freq_matrix = frequency_vectors(corpus, vocab)\n","\n","    # Calcular IDF (Inverse Document Frequency)\n","    doc_freq = np.sum(freq_matrix > 0, axis=0)\n","    idf = np.log(len(corpus) / (1 + doc_freq))\n","\n","    # Calcular TF-IDF\n","    tfidf_matrix = freq_matrix * idf\n","\n","    return tfidf_matrix\n","\n","tfidf_matrix = tfidf_representation(corpus)\n","print(tfidf_matrix)\n"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nqgUo1J44H92"},"outputs":[],"source":["def document_similarity(corpus, doc_index):\n","    # Obtener el vocabulario y la matriz TF-IDF del corpus completo\n","    vocab = get_vocab(corpus)\n","    tfidf_matrix = tfidf_representation(corpus)\n","\n","    # Calcular la similitud coseno entre el documento de interés y los demás documentos\n","    doc_tfidf = tfidf_matrix[doc_index]\n","    similarities = []\n","    for i in range(len(corpus)):\n","        if i != doc_index:\n","            similarity = cosine_similarity(doc_tfidf, tfidf_matrix[i])\n","            similarities.append((i, similarity))\n","\n","    # Ordenar los documentos por similitud coseno en orden descendente\n","    similarities.sort(key=lambda x: x[1], reverse=True)\n","\n","    # Obtener los índices de los documentos ordenados\n","    ordered_indices = [similarity[0] for similarity in similarities]\n","\n","    # Devolver los documentos ordenados por similitud coseno\n","    ordered_documents = [corpus[index] for index in ordered_indices]\n","\n","    return ordered_documents\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uamd5Oee4H93","outputId":"120105df-7909-4159-9846-56b4e409ea8b"},"outputs":[{"name":"stdout","output_type":"stream","text":["['martes el dia de hoy es martes', 'martes muchas gracias']\n","['que dia es hoy', 'martes muchas gracias']\n","['que dia es hoy', 'martes el dia de hoy es martes']\n"]}],"source":["    for idx in range(len(corpus)):\n","    ordered_documents = document_similarity(corpus, idx)\n","    print(ordered_documents)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}